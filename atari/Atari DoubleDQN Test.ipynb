{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import the gym module\n",
    "import gym\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=10):\n",
    "        '''첫 번째 트릭 No-Operation. 초기화 후 일정 단계에 이를때까지 아무 행동도 하지않고\n",
    "        게임 초기 상태를 다양하게 하여 특정 시작 상태만 학습하는 것을 방지한다'''\n",
    "\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(\n",
    "                1, self.noop_max + 1)  # pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a breakout environment\n",
    "env = gym.make('BreakoutNoFrameskip-v4')\n",
    "env = NoopResetEnv(env, noop_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = cv2.resize(img, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    return np.expand_dims(img, 0) # (1, 80, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "for _ in range(30):\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33c84e49e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "for _ in range(30):\n",
    "    s, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "plt.imshow(preprocess(s)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random \n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.deque = deque(maxlen=capacity)\n",
    "\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.deque.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.deque, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameHistory(object):\n",
    "    # consecutive frame을 4개씩 병합하여 새로운 x를 하나씩 만드는 클래스\n",
    "    # 만들어진 x는 4개씩 concat하고 s를 만들어서 DQN의 input으로 들어감\n",
    "    def __init__(self, env, k=4):\n",
    "        self.state_deque = deque(maxlen=k) # [x1, x2, x3, x4]\n",
    "        self.frame_history_deque = deque(maxlen=k) #[s1, s2, s3, s4]\n",
    "        self.k = k\n",
    "        \n",
    "        # 최초에는 초기 화면(env.reset)으로 채워둠\n",
    "        self.env = env\n",
    "        self.initial_state = self.preprocess(self.env.reset())\n",
    "        self.reset()\n",
    "        \n",
    "    def preprocess(self, img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        return np.expand_dims(img, 0) # (1, 80, 80)\n",
    "    \n",
    "    def append_frame(self, s):\n",
    "        # if full, aggregate and clear old frames, append new frame to history queue\n",
    "        self.frame_history_deque.append(self.preprocess(s))\n",
    "        \n",
    "        if len(self) == self.k:\n",
    "            self.state_deque.append(self.aggregate_frame())\n",
    "        return\n",
    "        \n",
    "    def aggregate_frame(self):\n",
    "        if len(self) < self.k:\n",
    "            raise ValueError('not enough frames in history, expected %s, but got %s'%(self.k, len(self)))\n",
    "        \n",
    "        # element-wise maximum to aggregate\n",
    "        frame_history = [self.frame_history_deque.popleft() for _ in range(self.k)]\n",
    "        return np.maximum.reduce(frame_history[-2:]) #마지막 2 프레임 사용 \n",
    "    \n",
    "    def get_state(self):\n",
    "        S = np.array([self.state_deque[i] for i in range(self.k)]) # S = [x1, x2, x3, x4], (4, 1, 80, 80)\n",
    "        S = np.swapaxes(S, 0, 1) # (1, 4, 80, 80)\n",
    "        return S\n",
    "    \n",
    "    def reset(self):\n",
    "        self.frame_history_deque = deque(maxlen=k)\n",
    "        self.state_deque = deque(maxlen=k)\n",
    "        \n",
    "        for _ in range(self.k):\n",
    "            self.state_deque.append(self.initial_state)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frame_history_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_dim, n_action):\n",
    "        super(DQN, self).__init__()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, 32, (8, 8), stride=4), nn.ReLU(), # conv 1\n",
    "            nn.Conv2d(32, 64, (4, 4), stride=2), nn.ReLU(), # conv 2\n",
    "            nn.Conv2d(64, 64, (3, 3), stride=1), nn.ReLU() # conv 3\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 512), nn.ReLU(), # hidden layer\n",
    "            nn.Linear(512, n_action)\n",
    "        )\n",
    "        \n",
    "    def to_tensor(self, img):\n",
    "        img = torch.tensor(img, dtype=torch.float32, device=self.device).cuda(non_blocking=True) # to tensor\n",
    "        img /= 255                                   # normalize into 0-1\n",
    "        while img.dim() < 4 :                        # 4-dim\n",
    "            img = img.unsqueeze(0)\n",
    "        return img\n",
    "        \n",
    "    def forward(self, frames):\n",
    "        frames = self.to_tensor(frames) \n",
    "        conved = self.conv(frames)\n",
    "        conved = conved.view(conved.size(0), -1)\n",
    "        output = self.fc(conved)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def weight_init(m):\n",
    "    '''\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        init.normal_(m.bias.data)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "k = 4 ## number of skipped frame\n",
    "#############\n",
    "\n",
    "behavior_net = DQN(in_dim=k, n_action=4)\n",
    "target_net = DQN(in_dim=k, n_action=4)\n",
    "\n",
    "behavior_net.to(behavior_net.device) # model to cuda\n",
    "target_net.to(target_net.device)     # model to cuda\n",
    "\n",
    "behavior_net.load_state_dict(torch.load('BreakoutDoubleDQN_state_dict'))\n",
    "target_net.load_state_dict(torch.load('BreakoutDoubleDQN_state_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter():\n",
    "    def __init__(self, env, behavior_net, target_net, k=4, train_method='DQN'):\n",
    "        self.env = env\n",
    "        self.train_method = train_method\n",
    "        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # networks\n",
    "        self.behavior_net = behavior_net\n",
    "        self.target_net = target_net\n",
    "        self.behavior_net.to(self.behavior_net.device) # model to cuda\n",
    "        self.target_net.to(self.target_net.device)     # model to cuda\n",
    "        \n",
    "        # train parameters\n",
    "        self.gamma = 0.99 #as written in paper\n",
    "        self.criterion = nn.SmoothL1Loss() # huber loss (error-clipping)\n",
    "        self.optim = torch.optim.RMSprop(self.behavior_net.parameters(), lr=0.00025, alpha=0.95, eps=0.01) #as written in paper in Rainbow\n",
    "        self.k = k\n",
    "        \n",
    "        # train details\n",
    "        self.total_frame = 0\n",
    "        self.total_episode = 0\n",
    "        \n",
    "        self.test_e = 0.05\n",
    "        self.batch_size = 32\n",
    "        self.max_replay = 250000 # not as written in paper\n",
    "        self.min_replay = 50000 # not as written in the paper\n",
    "        self.replay_memory = ReplayMemory(self.max_replay)\n",
    "        self.frame_history = FrameHistory(env=self.env, k=self.k)\n",
    "        \n",
    "        self.train_reward_ls = []\n",
    "        self.test_reward_ls = []\n",
    "    \n",
    "    # train-epsilon\n",
    "    @property\n",
    "    def train_e(self):\n",
    "        return np.max([1 - 9.0*1e-07*self.total_frame, 0.1])\n",
    "    \n",
    "    \n",
    "    def reset_episode(self):\n",
    "        # game(episode) begins\n",
    "        self.env.reset()  \n",
    "        self.frame_history.reset() #frame history reset\n",
    "        self.current_episode_frame = 0         # each episode의 frame 수 \n",
    "        self.current_episode_reward = 0        # each episode의 reward 합\n",
    "        self.current_life = 5\n",
    "    \n",
    "    def choose_action(self, S, e):\n",
    "        # at the beginning of an episode, do something\n",
    "        if self.current_episode_frame == 0:\n",
    "            a = 1\n",
    "        else:\n",
    "            # Choose an action by e-greedy\n",
    "            if np.random.rand(1) < e :\n",
    "                a = self.env.action_space.sample()\n",
    "            else:\n",
    "                q_behavior = self.behavior_net(S)\n",
    "                a = torch.argmax(q_behavior).item()\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    def run_k_frames(self, e):\n",
    "        # choose action!\n",
    "        S = self.frame_history.get_state()\n",
    "        a = self.choose_action(S, e)\n",
    "        r_sum = 0\n",
    "        \n",
    "        # repeat the action k-times\n",
    "        for _ in range(self.k):\n",
    "            s_next, r, done, info = self.env.step(a)\n",
    "            self.frame_history.append_frame(s_next)\n",
    "            r_sum += self.clip_reward(r) # store clipped reward for future training replay(experience)\n",
    "            \n",
    "            # accumulate history\n",
    "            self.current_episode_frame += 1\n",
    "            self.current_episode_reward += r\n",
    "            \n",
    "            # if episode(game) ends, return done(True)\n",
    "            if done: \n",
    "                return done\n",
    "            \n",
    "        # concat last k-frames into a next state S_next\n",
    "        S_next = self.frame_history.get_state()\n",
    "        \n",
    "        # Terminal when lose life\n",
    "        if info['ale.lives'] < self.current_life:\n",
    "            self.current_life = info['ale.lives']\n",
    "            terminal = True\n",
    "            self.replay_memory.append(S, a, r_sum, S_next, terminal) # save replay(experience)\n",
    "        \n",
    "        else:\n",
    "            self.replay_memory.append(S, a, r_sum, S_next, done) # save replay(experience)\n",
    "            \n",
    "        return done\n",
    "\n",
    "    \n",
    "    def train(self, max_total_frame):\n",
    "        while self.total_frame < max_total_frame :\n",
    "            # episode starts!\n",
    "            self.reset_episode()\n",
    "            \n",
    "            done = False\n",
    "            while not done:\n",
    "                done = self.run_k_frames(e=self.train_e)\n",
    "                \n",
    "                # training when enough replay-memory, every k-frames\n",
    "                if len(self.replay_memory) > self.min_replay:\n",
    "                    self.train_batch(self.batch_size)   \n",
    "                    self.total_frame += self.k\n",
    "                    \n",
    "                    # update target_net every 10,000 updates\n",
    "                    if self.total_frame%(self.k*10000)== 0 :\n",
    "                        self.update_target()\n",
    "                \n",
    "            # single-episode(game) is now done\n",
    "            # if not enough memory, save more\n",
    "            if len(self.replay_memory) < self.min_replay:\n",
    "                print('Not enough replay yet, expected more than %s, but %s instead'%(self.min_replay, len(self.replay_memory)))\n",
    "            \n",
    "            # if enough memory, print train result\n",
    "            else:\n",
    "                print('Train Episode :%s, Total Frame : %s, Train reward : %s,'%(self.total_episode, self.total_frame, self.current_episode_reward))\n",
    "                self.total_episode += 1\n",
    "                self.train_reward_ls.append(self.current_episode_reward)\n",
    "            \n",
    "                # testing, every 10 episodes when enough replay\n",
    "                if self.total_episode%10 == 0:\n",
    "                    self.test()           \n",
    "\n",
    "    def train_batch(self, batch_size):\n",
    "        # get mini-batch from replay-memory\n",
    "        S, A, R, S_next, D = self.replay_memory.sample(batch_size)\n",
    "        A = self.to_tensor(A, dtype=torch.long)\n",
    "        R = self.to_tensor(R, dtype=torch.float32)\n",
    "        D = self.to_tensor(D, dtype=torch.float32)\n",
    "        \n",
    "        q_behaviors = self.behavior_net(S)                # Q-values for every possible actions\n",
    "        q_behavior = self.select_indices(q_behaviors, A) # select Q-value for given actions\n",
    "        \n",
    "        if self.train_method=='DQN':\n",
    "            q_targets_next = self.target_net(S_next)   # Q-values of every possible actions next state (targetDQN)\n",
    "            q_target_next = q_targets_next.max(1)[0]   # max Q-values of next state\n",
    "            q_target = R + self.gamma*q_target_next*(1-D) \n",
    "        \n",
    "        elif self.train_method=='DoubleDQN':\n",
    "            next_actions = torch.argmax(self.behavior_net(S_next), dim=1) # choose argmax behavior actions at S_next\n",
    "            \n",
    "            q_targets_next = self.target_net(S_next) # cal Q-values of every possible actions next state (targetDQN)\n",
    "            q_target_next = self.select_indices(q_targets_next, next_actions) # select Q-value for next behavior actions\n",
    "            q_target = R + self.gamma*q_target_next*(1-D)\n",
    "        \n",
    "        # update weights\n",
    "        self.optim.zero_grad()\n",
    "        loss = self.criterion(q_target, q_behavior)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return\n",
    "        \n",
    "    def to_tensor(self, x, dtype=torch.float):\n",
    "        return torch.tensor(x, dtype=dtype, device=self.device)\n",
    "    \n",
    "    def select_indices(self, tensor, indices, dim=1):\n",
    "        if type(indices) != torch.Tensor:\n",
    "            indices = self.to_tensor(indices, dtype=torch.long)\n",
    "        if indices.dim() < 2 :\n",
    "            indices = indices.unsqueeze(1)\n",
    "        return tensor.gather(dim, indices).squeeze(1)\n",
    "    \n",
    "    def clip_reward(self, r):\n",
    "        return np.sign(r)\n",
    "    \n",
    "    \n",
    "    def update_target(self):\n",
    "        print('Update Target')\n",
    "        self.target_net.load_state_dict(self.behavior_net.state_dict())\n",
    "        return \n",
    "    \n",
    "    def test(self):\n",
    "        self.reset_episode()\n",
    "        done=False\n",
    "        while not done:\n",
    "            done = self.run_k_frames(e=fitter.test_e) # e-greedy\n",
    "                \n",
    "        self.test_reward_ls.append(self.current_episode_reward)\n",
    "        print('※Test※ \\t Frames: %s \\t Score: %s'%(self.current_episode_frame, self.current_episode_reward))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = Fitter(env, behavior_net, target_net, k=k, train_method='DoubleDQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "※Test※ \t Frames: 4887 \t Score: 52.0\n"
     ]
    }
   ],
   "source": [
    "fitter.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(fitter):\n",
    "    fitter.reset_episode()\n",
    "    img = plt.imshow(fitter.env.render(mode='rgb_array')) # only call this once\n",
    "    e = 0.02\n",
    "    \n",
    "    done=False\n",
    "    while not done:\n",
    "        img.set_data(fitter.env.render(mode='rgb_array')) # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        fitter.run_k_frames(e)\n",
    "    \n",
    "    fitter.env.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-43b622ce000e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-667292edd54c>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(fitter)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just update the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/fin/anaconda3/envs/tf2/lib/python3.6/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2053\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m                     bbox = ax.get_tightbbox(renderer,\n\u001b[0;32m-> 2280\u001b[0;31m                             bbox_extra_artists=bbox_extra_artists)\n\u001b[0m\u001b[1;32m   2281\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m                     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4396\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4397\u001b[0m             if (bbox is not None and\n\u001b[1;32m   4398\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m         \u001b[0;31m# that have been set by `fig.align_ylabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2289\u001b[0m         \u001b[0;31m# if we want to align labels from other axes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2291\u001b[0;31m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;31m# NB: always update labels and position to avoid issues like #9397\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval_contains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_game(fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
